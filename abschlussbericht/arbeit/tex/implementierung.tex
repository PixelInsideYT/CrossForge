% vim: set ts=4 sw=4 smartindent expandtab textwidth=100:

\section{Entity Component System}
Zu Beginn der Implementierung wurde über verschiedene Entity Component Systeme (ECS) recherchiert. Die folgenden Kriterien wurden bei der Auswahl eines passenden ECS berücksichtig. 
\begin{itemize}
	\item Aktive Entwicklung
	\item Datum des letzten Updates
	\item Unterstützte Sprachen
	\item Qualität der Dokumentation
	\item Performance
	\item Unterstützung des Open-Source-Paketmanager vcpkg
\end{itemize}
Bei der Recherche wurden, die folgenden zwei ECS, Flecs und EnTT, in Betracht gezogen. Letztendlich fiel die Wahl auf Flecs, da dieses besser dokumentiert ist und das letzte Update aktueller war. 
Im Anschluss an die Recherche wurde Flecs mit Hilfe von vcpkg eingebunden. Im Laufe des Projekts wurden die Entities Spieler, Pflanzen und Roboter angelegt und erhielten Komponenten, wie beispielsweise Fahr-, Spieler- und Pflanzenkomponente. So enthält zum Beispiel die Positionskomponente Informationen über die Translation, Rotation, Skalierung, Translationsdelta, oder Rotationsdelta. Die Pflanzenkomponente speichert, wie viel Wasser sich in der Pflanze befindet und wie viel maximal in den Topf passt. Und die Spielerkomponente hat Informationen über den Gamestate, die Kamera, Tastatur und Maus. Des Weiteren wurde die Steuerung der Kamera angepasst. Es wurde die Maus in dem Fenster gefangen, wodurch es nun möglich ist die Kamera zu bewegen, ohne vorher eine Maustaste drücken zu müssen. Außerdem wurde die Bewegungsgeschwindigkeit des Spielers in Bezug auf das Gehen und Rennen angepasst.
Zudem wurden Systeme, wie das Fahrsystem, Pflanzensystem, Gießsystem und noch viele mehr umgesetzt. Das Pflanzensystem, reduziert bei jedem Aufruf den Wasserstand aller Pflanzen, welches alle Objekte sind, die eine Pflanzenkomponente besitzen. Der Stand kann dabei jedoch nicht negativ werden. Ein weiteres Beispiel ist das „FindePflazensystem“, welches aus allen Pflanzen diejenige aussucht, welche am wenigsten Wasser hat und diese als neues Ziel festlegt. 
Da bei der Implementierung einige Komponenten und Systeme erzeugt werden, ist es wichtig sicherzustellen, dass man den Überblick über diese behält. Aus diesem Grund wurden im Laufe des Projekts Aufräumarbeiten durchgeführt. Das bedeutet, es wurden Komponenten entfernt, die nicht mehr benötigt wurden. Der Rest wurde in einer Datei zusammengefasst. Das erleichtert zum einen das Einbinden von diesen in anderen Dateien, zum anderen findet man sie leichter. Das Gleiche wurde mit kleinen Systemen gemacht, wie beispielsweise dem AIsystem, dem Pflanzensystem und den beiden Gießsystemen.  

\section{Multiagenten System}

\subsection{Sate Machines}

Wir haben noch keine State Machines für den Roboter implementiert, weil der Roboter sich nur in den zwei Zuständen \"Pflanzen gießen\" und \"Mit Spieler reden\" befinden kann. Diese Funktionalität kann über ein einfaches if-else abgedeckt werden und deswegen sind State Machines noch nicht nötig.

\subsection{Behaviour Tree}
Um den Behaviour Tree für den Handlungsablauf des Roboters effizient umzusetzen, wurde die Bibliothek BehaviorTree.CPP genutzt. Diese wurde ausgesucht, da sie vcpkg unterstützt, für C++ entwickelt wurde und alle nötigen Funktionalitäten bietet, ohne zu komplex zu sein. 
Im Falle des Gießroboters gibt es fünf Schritte, die er ausführen muss, um eine Pflanze zu gießen. Zuerst muss eine Pflanze ausgewählt werden, die am wenigsten Wasser hat. Im Anschluss wird der Weg von der aktuellen Position zu dieser gesucht. Daraufhin fährt der Roboter den Weg ab. Dort angekommen muss er sich noch so drehen, dass sich sein Gießarm über dem Blumentopf befindet, damit am Ende die Pflanze gegossen werden kann. Alle diese Schritte wurden in dem Behaviour Tree als Blattknoten implementiert. Darüber sitzt ein sogenannter Sequenzknoten, dieser merkt sich welches Blatt als letztes ausgeführt wurde und ob dieses beendet wurde. Wenn es noch nicht fertig ist, wird es im nächsten Schritt erneut aufgerufen. Dies geschieht so lang, bis das Blatt fertig ist. Der Sequenzknoten erhält als Rückmeldung „SUCCES“, oder, wenn das Blatt noch nicht fertig ist, „RUNNING“. Wenn ein Blatt fertig ist, wird das nächste ausgeführt. Wurde jedes Blatt einmal ausgeführt und hat jeweils „SUCCES“ zurückgegeben, so beginnt der Sequenzknoten erneut das erste Blatt aufzurufen. 
Die Baumstruktur wird in einem XML-Dokument gespeichert, die Funktionalität der einzelnen Knoten befindet sich in einer C++ Datei und die Knoten und Blätter werden in einer sogenannten Treefactory erstellt, welche ebenfalls in C++ geschrieben ist.
\subsection{Steering Behaviour}
Auch die Bewegungssteuerung wurde auf Basis des ECS implementiert. Dazu wurden ein Fahrsystem und Komponente, wie ein Fahrkomponente, Hinderniskomponente, Pfadkomponente und eine Positionskomponente, erstellt. Das Fahrsystem untersucht dabei, welcher Bewegungsmodus aktuell ausgewählt ist und passt darauf basierend das Bewegungsverhalten an. Es wird zwischen dem Pfadverfolgen und Drehen unterschieden. Ist Pfadverfolgen aktiviert, so folgt der Roboter einem Pfad, welcher sich in der Pfadkomponente befindet, die dem Entity Roboter zugeordnet wird. Der Pfad ist dabei eine Liste von Wegpunkten, die der Agent abfahren soll. Dazu wird das, wie im Konzeptteil beschriebene, Suchverhalten genutzt. Zudem wird, während der Roboter die Punkte abfährt, darauf geachtet, dass er mit keinen Hindernissen kollidiert. Dazu zählen alle Objekte in der Szene, welche eine Hinderniskomponente haben. In dieser ist der Radius des Gegenstandes oder Spielers gespeichert. Damit das Fahrverhalten des Roboters sichtbar ist, muss die Position in der Positionskomponente nach jedem Durchlauf aktualisiert werden. Das Ausweichverhalten wurde, wie im Konzeptteil beschrieben, implementiert. Das bedeutet, es wird überprüft, ob das Objekt, welches am nächsten zu dem Roboter ist, sich vor dem Agenten befindet. Ist dies der Fall, so wird geschaut, ob der Roboter nach dem nächsten Schleifendurchlauf mit diesem kollidiert, wenn ja wird der aktuelle Wegpunkt nach rechts oder links verschoben. Es wird dabei berücksichtigt, bei welcher Verschiebung die Abweichung zum Pfad am geringsten ist. Je nach dem wird der Pfad angepasst. Da der Punkt nun eine neue Position hat, weicht der Roboter dem Hindernis aus.
Soll der Roboter sich nun drehen, um beispielsweise mit dem Spieler zu reden, oder um eine Pflanze zu gießen, muss in der Fahrkomponente der aktuelle Modus auf Drehen gesetzt werden. In ihr sind zudem Informationen über die Masse, die Höchstgeschwindigkeit, die maximale Lenkkraft und die Größe des Sicherheitsabstandes gespeichert. Bei der Implementierung des Drehverhaltens, werden jedoch keine weiteren Punkte bestimmt, die der Agent anschauen soll, sondern der Drehwinkel wird interpoliert. Das bedeutet, dass der Wert für diesen reduziert wird, sodass der Roboter sich unabhängig von der Framerate langsam in die richtige Richtung dreht und zum Schluss korrekt ausgerichtet ist. Alle Objekte, die sich nun in dem Projekt bewegen sollen, erhalten eine Fahrkomponente, aktuell sind dies jedoch nur die zwei Gießroboter. 
Die Bewegungssteuerung hat jedoch noch zahlreiche Probleme. Da die Steuerung des Roboters auf einfachen mathematischen Formeln basiert, verfügt der Roboter nur über ein stark eingeschränktes Wissen über die Umgebung. Aus diesem Grund kann er zwar einem Hindernis ausweichen, es wird jedoch dabei immer nur ein Objekt berücksichtigt. Das bedeutet, dass er beispielsweise rechts an einem Hindernis vorbeifährt und damit auf einen Kollisionskurs mit einem anderen Gegenstand gerät, was nicht passiert wäre, wenn er dem ersten Hindernis auf der linken Seite ausgewichen wäre. Hätte der Roboter ein besseres Verständnis über die aktuelle Situation, so könnte er sich optimaler in der Welt bewegen. Zudem wird bei dem Ausweichverhalten nicht zwischen Objekten unterschieden, die stillstehen, oder sich bewegen. Es könnte passieren, dass er einen Bogen nach rechts fährt, um einem Objekt auszuweichen, dieses sich jedoch so bewegt, dass es trotz Ausweichmanöver immer noch im Weg befindet. Im Schlimmsten Fall könnte dieses Hindernis sich aufgrund seiner Bewegung dauerhaft zwischen Roboter und Ziel befinden. In dieser Situation wäre es für ihn mit dem aktuell implementierten Bewegungssystem unmöglich die Pflanze zu erreichen. Würde der Roboter ein besseres Verständnis über die Umgebung besitzen, so könnte er einfach nach links ausweichen.
Des Weiteren kann auf Grund der Simplizität nicht garantiert werden, dass der Roboter, während er auf eine Pflanze zufährt, nicht auf eine Kreisbahn um diese gelangt. Dies würde geschehen, wenn das Ziel sich links beziehungsweise rechts von dem Roboter befindet und er eine Kurve fahren muss, um es zu erreichen. Wenn die Krümmung der Kurve stärker ist als der Roboter mit seinem maximalen Lenkwinkel fahren kann, ist es für ihn unmöglich diesen Pfad zu fahren. Im schlimmsten Fall befindet sich das Ziel im Mittelpunkt der Kurve, die der Roboter aktuell fährt. Dies hätte zur Folge, dass sich der Abstand zur Pflanze nicht verändert und er sie nicht erreichen kann. Das aktuell implementierte Bewegungssystem kann nicht erkennen, ob er auf einer Kreisbahn ist. Daher können auch keine Korrekturzüge ausgeführt werden.
Außerdem ist die Bewegungssteuerung nicht intuitiv, da Eigenschaften, wie die Masse des Roboters oder seine maximale Krafteinwirkung dieses beeinflussen. Es ist dementsprechend bei der Erstellung neuer Roboter schwierig passende Werte für diese Merkmale zu finden, um das gewünschte Fahrverhalten zu erhalten. 
Während der Programmierung sind zahlreiche Herausforderungen aufgetreten. Durch sorgfältiges Analysieren und Zusammenarbeiten konnten jedoch alle Probleme im Verlauf des Projekts bewältigt werden.
\section{Partikelsystem}
Um das Partikelsystem in dem Projekt umzusetzen, wurden zwei neue Komponenten mit zusätzlich zwei neuen Systemen implementiert. Die Komponenten waren dabei eine Emiter- und eine Partikelkomponente. Die Emiterkomponente enthält Informationen über die Anzahl der Partikel, die pro Iteration erschaffen werden und die relative Position, wo dies geschehen soll. In dem Projekt muss berücksichtigt werden in welche Richtung der Roboter schaut, damit die Wassertropfen auch wirklich an der Stelle erscheinen, wo sich der Arm des Roboters befindet. In der Partikelkomponente wird die sogenannte Lebensdauer gespeichert, damit die Tropfen nach einer definierten Zeit auch wieder verschwinden bzw. entfernt werden können. Das ist sehr wichtig, da sonst immer mehr Entities erschaffen werden, was die Performance stark reduzieren würde und im schlimmsten Fall das Programm zum Absturz bringen kann. Das Partikelsystem erschafft Objekte mit einer Partikelkomponente, Geometriekomponente und einer Positionskomponente. Die Geometriekomponente ist dabei wichtig, um den einzelnen Tropfen ein Modell zuzuordnen, anderenfalls wäre der Benutzer nicht in der Lage das Wasser zu sehen. Bei der Erstellung der Entities wird zudem darauf geachtet, dass die Position, an der sie erschaffen werden, leicht variiert. Dadurch entsteht ein breiterer Strahl aus Tropfen, was das Gießen realistischer darstellt. Das zweite System ist das PartikelRemovalSystem. Dieses reduziert bei jeder Iteration den Wert der Lebensdauer aller Tropfen, bis dieser kleiner gleich Null ist. In diesem Fall wird dann das entsprechende Objekt entfernt. 
\section{Navigationssystem}

Um einen Pfad für ein Entity zu finden, muss man dem Entity eine PathRequestComponent mit Start und Ziel hinzufügen. Das Navigationssystem ließt die Daten aus dem Request aus, entfernt diesen und fügt stattdessen eine PathComponent mit dem gefundenen Pfad hinzu.

Um einen Pfad von einem Startpunkt zu einem Zielpunkt zu finden, sind drei Schritte nötig. Zuerst muss man die Navigationsnetzpolygone finden, auf denen Start und Ziel liegen. Danach sucht man die Polygone, die Start- und Zielpolygon verbinden und zum Schluss kann man diese Liste an Polygonen zu einem Pfad aus Punkten umwandeln.

\section{Physiksystem}

Die ECS-Bibliothek Flecs unterstützt Entity Event Listener, sogenannte Observer. Man kann eine Callbackfunktion definieren die gerufen wird, wenn eine Komponente eines Entities hinzugefügt, modifiziert oder entfernt wird. Das Physiksystemsystem nutzt zwei Obsover: ein Observer überwacht, wenn eine Physikkomponente zu einem Entity hinzugefügt wird und fügt den enthaltenen Rigidbody auch in die Physikwelt ein. Der zweite Observer wird gerufen, wenn ein Entity aus der Welt entfernt wird, welches eine Physikkomponente besitzt. In dem Fall wird auch der dazugehörige Rigidbody aus der Physikwelt entfernt.

Theoretisch benötigen wir nur die Kollisionserkennung und -auflösung von Bullet. Aber es war deutlich schwerer diese beiden Funktionen getrennt von der Physiksimulation zu rufen als die Physikwelt und die ECS-Welt zu synchronisieren. Deswegen funktioniert die Kollisionserkennung und -auflösung jetzt in drei Schritten. Zuerst werden alle Entities mit Physikkomponente und Transformationskomponente gesucht und die Geschwindigkeit und Position der Transformationskomponente auf den Rigidbody der Physikkomponente übertragen. Dann wird die Simulation der Physikwelt mit dem jetzigen Zeitschritt gerufen. Zum Schluss wird die Geschwindigkeit und Position des Rigidbodies wieder in die Transformationskomponente geschrieben.

Die Platformen, Zäune und Wendeltreppe sind statische Geometrie und zusätzlich noch Konkav. Deswegen haben sind diese mit einem Dreieckskollider repräsentiert. Dabei wird einfach das 3D-Modell der statischen Geometrie als Collider benutzt.

Alle Entities haben Kapsel Collider anstatt Zylinder Collider, da diese an den Dreieckskanten der statischen Geometrie hängen geblieben sind.

\section{Szenen Editor}

Die Assimp Variante hat nicht funktioniert, weil die Eingriffe zu tief in der Engine vorgenommen werden mussten. Außerdem war das Abstraktionslevel zu gering: wenn man nur Knoten hat ist es schwer Entities zu erkennen.

Das Blender Plugin wurde in Python programmiert und man hat Zugriff auf alle Optionen, auf die man auch im Editor Zugriff hat. Um jetzt die Entities zu exportieren, wurde über alle Objekte der Szene iteriert und überprüft, ob diese gelinkt sind. Wenn das der Fall ist, dann wurde die Transformation, der Name und der Name der Modelldatei in eine JSON-Datei geschrieben. Um jetzt auch noch die statische Geometrie zu exportieren, wurden alle gelinkten Objekte unsichtbar gemacht und nur die sichtbaren Modelle wurden exportiert. Alle unsichtbaren Objekte wurden anschließend wieder sichtbar gemacht.

In CrossForge wurde dann die JSON-Datei geladen und für jeden Eintrag wurde ein entsprechendes Entity zu Welt hinzugefügt.

\section{Dialogsystem}

Die gesamte Implementierung des Dialogsystems haben wir (Lisa und Sophie) im Pair-Coding übernommen. 

\subsection{Imgui}

Die Bibliothek für Imgui konnte über vcpkg recht schnell und einfach in das Projekt eingebunden werden. Zur Erzeugung von Dialogfenstern erstellen wir mit Imgui Frames, in denen oben der aktuelle Text des Dialogs angezeigt wird und unten die möglichen Antworten als Buttons. Wir nutzen außerdem einige Style-Anpassungen, um den Dialog etwas anschaulicher für den Nutzer zu gestalten, sodass z.B. das Fenster immer im Viewport zentriert ist.

\subsection{JsonCpp}

Ähnlich wie Imgui konnten wir auch JsonCpp über vcpkg einbinden. Mithilfe dieser Bibliothek können wir dann den Dialoggraphen initialisieren. Dafür sollten die Json-Dateien die gleiche Baumstruktur aufweisen, wie der Dialoggraph selbst. Über JsonCpp werden die Informationen aus der Datei gelesen und gespeichert, sodass sie dann weiter genutzt werden können, um den Dialoggraph zu füllen.

\subsection{Dialoggraph}

Den Dialoggraph haben wir so wie im Konzeptteil bechrieben implementiert. In einer dafür erstellten Klasse werden die zuvor genannten Daten gespeichert: der Dialogtext, ein Boolean für die Unterscheidung zwischen Roboter und Spieler und die möglichen Antworten. Zusätzlich gibt es noch eine Funktion, die die Initialisierung des Baumes umsetzt und eine Funktion für das Ersetzen der Strings mithlfe der Dialogmap.

\subsection{Dialogmap}

Mit der implementierten Dialogmap kann eine Funktion aufgerufen werden, die den Name einer Pflanze zurückgibt. Der Rückgabewert dieser Funktion ist allerdings statisch festgelegt, da zum Zeitpunkt der Abgabe das Dialogsystem noch nicht in das ECS eingebunden ist. Diese Integration wäre aber notwendig um die Positionen von Roboter und Spieler zu ermitteln, die gebraucht werden um zu bestimmen welcher Pflanzenname zurückgegeben werden soll. Auch die Pflanzennamen selbst sind im ECS gespeichert, weshalb ein Zugriff darauf vom Dialogsystem aus aktuell nicht möglich ist.  
Weitere Funktionalitäten der Dialogmap, wie Eventhandling sind ebenfalls noch nicht implementiert.

\section{Modelle und Szene}

Wie bereits im >Konzept< beschrieben ging die Anfangszeit in die Konzeptbearbeitung hinein. Ebenso hat es etwas Zeit in Anspruch genommen sich in Blender einzuarbeiten. Alle Modelle wurden mehrmals modelliert aufgrund von verschiedenen Problemen, wie z.B. Designunklarheiten, zu viele Polygone innerhalb des Models aufgrund zu vieler Details oder falscher Vorgehensweise, oder anderen Extras etc. \includegraphics[height=0.3\pageheight,keepaspectratio]{pics/1} ersten robomodels, ersten blätter mit wireframe<
Die Modelle wurden via Blender hergestellt und die jeweils dazugehörigen Texturen wurden selbstständig auf dem iPad mit ProCreate gezeichnet.
Der Roboter wurde grundsätzlich aus einfachen Zylindern modelliert und entsprechend angepasst. Die Grundüberlegung bei diesem war es, dass er nicht zu klassisch ‚standartrobotermäßig‘ aussieht, da man mit ihm kommunizieren kann. Die Solarplatte auf seinem Kopf wurde mit der Intension bzw. Überlegung integriert, dass er sich über die Sonne aufladen kann. Der Arm soll einen Schlauch darstellen, mit dem die Pflanzen gegossen werden können. Alle einzelnen Objekte, bis auf den Schlauch, wurden zum Schluss zusammen gemerged. Der Schlauch blieb als einzelnes Objekt, da er im späteren Verlauf animierbar sein soll. Was die Texturen angeht, wurden bis auf die Solarplatte, alle direkt in Blender via Geometry Nodes eingestellt. Daher bekam der Körper den metallischen, und die Räder den gummiartigen Look. Die Solarplatte wurde in ProCreate selbst gezeichnet und im UV-Editor eingefügt und angepasst. Nach Absprachen mit dem Team entstand dann unser Roboter wie man ihn aktuell im MVP sehen kann. >BILD EINFÜGEN<
Die beiden Pflanzen sind relativ frei aus dem Kopf entstanden. Die einzigen Überlegungen dabei waren es, zwei unterschiedliche Pflanzen zu haben. Bei beiden entstanden die Blumentöpfe aus einfachen Zylindern. Der Stiel der kleineren Pflanze entstand anfangs erst aus einem einfachen Mesh mit verschiedenen Einstellungen der Geometry Nodes [1]. Diese Variante wurde allerdings verworfen und dann doch vereinfacht. Die Blätter, welche anfangs relativ 3D-getreu, aber zu detailliert waren bestehen jetzt nur noch aus zwei einfachen 2D-Texturen. Alle Texturen, sowohl Blätter als auch die Töpfe mit Erde, wurden in ProCreate selbstständig erstellt. Der erste versuch bestand daraus, die Modelle in ProCreate zu importieren und direkt darauf zu zeichnen. Diese Texturen hätten dann in Blender ganz einfach importiert werden können. Allerdings funktionierte diese Variante nicht ganz so wie erhofft, weswegen die Texturen dann einfach 2D gezeichnet wurden, und dann via UV-Mapping in Blender angepasst wurden. Wie auch bei dem Roboter wurden die Pflanzen nach Absprache mit dem Team abgesegnet und ins MVP aufgenommen. >BILD EINFÜGEN<
Die größere Hürde waren die Plattformen und deren Design. Wie bereits im Konzept beschrieben, entstanden da anfangs verschiedene Ideen. Beide Plattformen entstanden letzten Endes frei Hand und dazu eine etwas ausgefallenere Verbindung zwischen eben diesen Beiden. Damit die Roboter sich im Notfall auch zwischen den beiden Plattformen bewegen können, entstand dazu mit Inspiration noch eine Rampe um die Säule herum [2]. Damit sowohl die Rampe als auch die Plattformen etwas sicherer sind, bekamen diese noch jeweils einen Zaun und ein Geländer herum. Auch hier entstanden alle Texturen via ProCreate aus eigener Hand. Dieses Modell wurde ebenso mit dem Team abgesprochen, bevor es final war. >BILD EINFÜGEN< Am Ende wurde leider etwas zu spät aufgefallen, dass die Rampe breiter sein sollte, für den Fall, dass beide Roboter gleichzeitig die Ebenen wechseln wollen und sich auf der Rampe treffen. Zum aktuellen Zeitpunkt ist dort leider kein Platz zum Ausweichen und einer der Roboter driftet ab.
Nachdem alle Modelle fertig waren, wurden diese in der Szene zusammengesetzt und weitestgehend angepasst. Das Ganze wurde dann mithilfe eines Dropper Addon ins Projekt geladen. Hier gab es Anfangs einige Probleme und Unklarheiten, welche aber letzten Endes mit Hilfe des Teamleiters gelöst wurden. Um die Zusammenarbeit zwischen den Modellen und den restlichen Programmieraufgaben, wie das Navigationssystem, zu verbessern, wurden die Modelle in ‚linked‘ (Pflanzen und Roboter) und ‚static‘ (Plattformen & co) eingeteilt.
Als die Szene an sich so weit fertig war und auch im Projekt geladen war, gab es nur noch ein paar generelle Probleme zu lösen, was Texturen und einige Ordnerstrukturen anging.
Die nächste Aufgabe galt dann eigentlich die MVP-Szene weiter auszubauen und aufzuhübschen. Hierfür entstanden über ein neues Addon zwei Bäume und ein Haus. Auch hier wurden sowohl für die Bäume als auch für das Haus alle Texturen über ProCreate erstellt, wobei das Haus noch nicht ganz fertig war. >BILD EINFÜGEN< Aufgrund des Zeitlimits wurde der Ausbau der Szene allerdings vorzeitig abgebrochen.
