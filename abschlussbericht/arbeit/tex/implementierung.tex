% vim: set ts=4 sw=4 smartindent expandtab textwidth=100:

\section{Entity Component System}

\section{Multiagenten System}

\subsection{Sate Machines}

nicht mehr dazu gekommen, weil Zeit vorbei war und Aufgaben von anderen Projektteilnehmern übernommen werden musste
aber auch nicht nötig, weil Dialogsystem noch nicht fertig war

\subsection{Behaviour Tree}

\subsection{Steering Behaviour}

\section{Partikelsystem}

\section{Navigationssystem}

Keine Besonderheiten. Ist halt so wie im Konzept

\section{Physiksystem}

Da das Physiksystem mit Observern feststellt, ob eine Physikkomponente hinzugefügt wurde, muss die Komponente schon initialisiert sein und man kann die lazy Initialisierung nicht benutzen. Deswegen muss man Physikkomponenten mit emplace anstatt add zum Entity hinzufügen.

Die Platform und Wendeltreppe ist statische Geometrie und zusätzlich noch Konkav. Deswegen haben wir diese mit einem Dreieckskollider ausgestattet. Dabei wird einfach das 3D-Modell als Collider benutzt.

Alle Entities haben Kapsel Collider, da die Entities sonst an den Dreieckskanten der statischen Geometrie hängen geblieben sind.

\section{Szenen Editor}

Die Assimp Variante hat nicht funktioniert, weil die eingriffe zu tief in der Engine vorgenommen werden mussten. Außerdem war das Abstraktionslevel zu gering: wenn man nur Knoten hat ist es schwer Entities zu erkennen.

Das Blender Plugin wurde in Python programmiert und man hat zugriff auf alle Optionen, auf die man auch im Editor Zugriff hat. Um jetzt die Entities zu exportieren, wurde über alle Objekte der Szene iteriert und überprüft, ob diese gelinkt sind. Wenn das der Fall ist, dann wurde die Transformation, der Name und der Name der Modelldatei in eine JSON-Datei geschrieben. Um jetzt auch noch die statische Geometrie zu exportieren, wurden alle Entities unsichtbar gemacht und nur die sichtbaren Modelle wurden exportiert.

In CrossForge wurde dann die JSON-Datei geladen und für jeden Eintrag wurde ein entsprechendes Entity zu Welt hinzugefügt.

\section{Dialogsystem}

Die gesamte Implementierung des Dialogsystems haben wir (Lisa und Sophie) im Pair-Coding übernommen. 

\subsection{Imgui}

Die Bibliothek für Imgui konnte über vcpkg recht schnell und einfach in das Projekt eingebunden werden. Zur Erzeugung von Dialogfenstern erstellen wir mit Imgui Frames, in denen oben der aktuelle Text des Dialogs angezeigt wird und unten die möglichen Antworten als Buttons. Wir nutzen außerdem einige Style-Anpassungen, um den Dialog etwas anschaulicher für den Nutzer zu gestalten, sodass z.B. das Fenster immer im Viewport zentriert ist.

\subsection{JsonCpp}

Ähnlich wie Imgui konnten wir auch JsonCpp über vcpkg einbinden. Mithilfe dieser Bibliothek können wir dann den Dialoggraphen initialisieren. Dafür sollten die Json-Dateien die gleiche Baumstruktur aufweisen, wie der Dialoggraph selbst. Über JsonCpp werden die Informationen aus der Datei gelesen und gespeichert, sodass sie dann weiter genutzt werden können, um den Dialoggraph zu füllen.

\subsection{Dialoggraph}

Den Dialoggraph haben wir so wie im Konzeptteil bechrieben implementiert. In einer dafür erstellten Klasse werden die zuvor genannten Daten gespeichert: der Dialogtext, ein Boolean für die Unterscheidung zwischen Roboter und Spieler und die möglichen Antworten. Zusätzlich gibt es noch eine Funktion, die die Initialisierung des Baumes umsetzt und eine Funktion für das Ersetzen der Strings mithlfe der Dialogmap.

\subsection{Dialogmap}

Mit der implementierten Dialogmap kann eine Funktion aufgerufen werden, die den Name einer Pflanze zurückgibt. Der Rückgabewert dieser Funktion ist allerdings statisch festgelegt, da zum Zeitpunkt der Abgabe das Dialogsystem noch nicht in das ECS eingebunden ist. Diese Integration wäre aber notwendig um die Positionen von Roboter und Spieler zu ermitteln, die gebraucht werden um zu bestimmen welcher Pflanzenname zurückgegeben werden soll. Auch die Pflanzennamen selbst sind im ECS gespeichert, weshalb ein Zugriff darauf vom Dialogsystem aus aktuell nicht möglich ist.  
Weitere Funktionalitäten der Dialogmap, wie Eventhandling sind ebenfalls noch nicht implementiert.

\section{Modelle und Szene}

Wie bereits im >Konzept< beschrieben ging die Anfangszeit in die Konzeptbearbeitung hinein. Ebenso hat es etwas Zeit in Anspruch genommen sich in Blender einzuarbeiten. Alle Modelle wurden mehrmals modelliert aufgrund von verschiedenen Problemen, wie z.B. Designunklarheiten, zu viele Polygone innerhalb des Models aufgrund zu vieler Details oder falscher Vorgehensweise, oder anderen Extras etc. >BILD EINFÜGEN ersten robomodels, ersten blätter mit wireframe<
Die Modelle wurden via Blender hergestellt und die jeweils dazugehörigen Texturen wurden selbstständig auf dem iPad mit ProCreate gezeichnet.
Der Roboter wurde grundsätzlich aus einfachen Zylindern modelliert und entsprechend angepasst. Die Grundüberlegung bei diesem war es, dass er nicht zu klassisch ‚standartrobotermäßig‘ aussieht, da man mit ihm kommunizieren kann. Die Solarplatte auf seinem Kopf wurde mit der Intension bzw. Überlegung integriert, dass er sich über die Sonne aufladen kann. Der Arm soll einen Schlauch darstellen, mit dem die Pflanzen gegossen werden können. Alle einzelnen Objekte, bis auf den Schlauch, wurden zum Schluss zusammen gemerged. Der Schlauch blieb als einzelnes Objekt, da er im späteren Verlauf animierbar sein soll. Was die Texturen angeht, wurden bis auf die Solarplatte, alle direkt in Blender via Geometry Nodes eingestellt. Daher bekam der Körper den metallischen, und die Räder den gummiartigen Look. Die Solarplatte wurde in ProCreate selbst gezeichnet und im UV-Editor eingefügt und angepasst. Nach Absprachen mit dem Team entstand dann unser Roboter wie man ihn aktuell im MVP sehen kann. >BILD EINFÜGEN< 
Die beiden Pflanzen sind relativ frei aus dem Kopf entstanden. Die einzigen Überlegungen dabei waren es, zwei unterschiedliche Pflanzen zu haben. Bei beiden entstanden die Blumentöpfe aus einfachen Zylindern. Der Stiel der kleineren Pflanze entstand anfangs erst aus einem einfachen Mesh mit verschiedenen Einstellungen der Geometry Nodes [1]. Diese Variante wurde allerdings verworfen und dann doch vereinfacht. Die Blätter, welche anfangs relativ 3D-getreu, aber zu detailliert waren bestehen jetzt nur noch aus zwei einfachen 2D-Texturen. Alle Texturen, sowohl Blätter als auch die Töpfe mit Erde, wurden in ProCreate selbstständig erstellt. Der erste versuch bestand daraus, die Modelle in ProCreate zu importieren und direkt darauf zu zeichnen. Diese Texturen hätten dann in Blender ganz einfach importiert werden können. Allerdings funktionierte diese Variante nicht ganz so wie erhofft, weswegen die Texturen dann einfach 2D gezeichnet wurden, und dann via UV-Mapping in Blender angepasst wurden. Wie auch bei dem Roboter wurden die Pflanzen nach Absprache mit dem Team abgesegnet und ins MVP aufgenommen. >BILD EINFÜGEN<
Die größere Hürde waren die Plattformen und deren Design. Wie bereits im Konzept beschrieben, entstanden da anfangs verschiedene Ideen. Beide Plattformen entstanden letzten Endes frei Hand und dazu eine etwas ausgefallenere Verbindung zwischen eben diesen Beiden. Damit die Roboter sich im Notfall auch zwischen den beiden Plattformen bewegen können, entstand dazu mit Inspiration noch eine Rampe um die Säule herum [2]. Damit sowohl die Rampe als auch die Plattformen etwas sicherer sind, bekamen diese noch jeweils einen Zaun und ein Geländer herum. Auch hier entstanden alle Texturen via ProCreate aus eigener Hand. Dieses Modell wurde ebenso mit dem Team abgesprochen, bevor es final war. >BILD EINFÜGEN< Am Ende wurde leider etwas zu spät aufgefallen, dass die Rampe breiter sein sollte, für den Fall, dass beide Roboter gleichzeitig die Ebenen wechseln wollen und sich auf der Rampe treffen. Zum aktuellen Zeitpunkt ist dort leider kein Platz zum Ausweichen und einer der Roboter driftet ab.
Nachdem alle Modelle fertig waren, wurden diese in der Szene zusammengesetzt und weitestgehend angepasst. Das Ganze wurde dann mithilfe eines Dropper Addon ins Projekt geladen. Hier gab es Anfangs einige Probleme und Unklarheiten, welche aber letzten Endes mit Hilfe des Teamleiters gelöst wurden. Um die Zusammenarbeit zwischen den Modellen und den restlichen Programmieraufgaben, wie das Navigationssystem, zu verbessern, wurden die Modelle in ‚linked‘ (Pflanzen und Roboter) und ‚static‘ (Plattformen & co) eingeteilt.
Als die Szene an sich so weit fertig war und auch im Projekt geladen war, gab es nur noch ein paar generelle Probleme zu lösen, was Texturen und einige Ordnerstrukturen anging.
Die nächste Aufgabe galt dann eigentlich die MVP-Szene weiter auszubauen und aufzuhübschen. Hierfür entstanden über ein neues Addon zwei Bäume und ein Haus. Auch hier wurden sowohl für die Bäume als auch für das Haus alle Texturen über ProCreate erstellt, wobei das Haus noch nicht ganz fertig war. >BILD EINFÜGEN< Aufgrund des Zeitlimits wurde der Ausbau der Szene allerdings vorzeitig abgebrochen.

\section{Management}

Der nächste Abschnitt ist aus der Ich-Perspektive des Projektmanagers (Linus) geschrieben, weil das einfacher ist.

Unser Praktikumsteam bestand aus sechs Personen mit unterschiedlichen Wissensständen, weswegen ich die Aufgaben generell nach Schwierigkeit und Fähigkeiten der Bearbeiter verteilt habe. Angelique bricht ihr Informatikstudium ab und bekommt deshalb die kreative Aufgabe die Modelle und Szene zu erstellen. Lisa und Sophie haben noch sehr wenig Erfahrung und sollten deshalb die einfachsten Themen angehen. Leon auch noch wenig Erfahrung aber dafür eine gewisse leidensfähigkeit. Mittelschwere bis schwere Aufgaben hat er ohne Widerstand in Angriff genommen. Carlo und ich haben die meiste Erfahrung und arbeiten auch schon mehrere Stunden in der Woche als Werkstudenten. Deswegen haben wir die uns auf schwersten Probleme fokusiert.

Als Team haben uns darauf geeinigt mindestens sechs Stunden in der Woche dem Teamorientierten Praktikum zu widmen, da mehr neben Studium und Arbeit nicht möglich war. Deswegen haben wir uns auch gegen einen Scrum Prozess entschieden, weil die Retros, Plannings und Sprintwechsel zu viel Zeit in Anspruch nehmen. Um uns zu organisieren wollten wir Jira einsetzen, jedoch hat die Software niemand wirklich benutzt. Da der Fortschritt langsam war konnte man auch ohne Hilfsmittel sehr gut den Überblick darüber behalten, wer an was gearbeitet hat.

Wir haben uns einmal in der Woche, entweder über Discord oder in Präsenz, getroffen um uns zum Projektfortschritt zu synchronisieren. Da die meisten mit ihrer Aufgabe überfordert waren und nicht wussten, wo sie anfangen sollten habe ich mit Lisa, Sophie und Leon jeweils eine Stunde in der Woche eine Pair-Coding-Session gehalten. Das hatte den großen Vorteil, dass ich dann genau wusste, wer welchen Fortschritt hat. Dem gegenüber standen zwei große Nachteile. Erstens konnte ich somit keine Features implementieren, weil meine sechs Stunden voll mit Pair Coding und Management waren und zweitens ist es sehr verlockend bei jeder kleinen Hürde aufzugeben und auf das nächste Pair Coding zu warten, weil es dort ja sowieso gelöst wird.

Nach den Sommerferien habe ich eine Retrospektive vorbereitet und mit dem gesamten Team durchgeführt. Dabei haben sich verschiedene bevorzugte Arbeitsweisen heraus kristallisiert. Während Leon die Pair Coding Sessions bevorzugt und weiter führen möchte, sagen Lisa und Sophie, dass sie ihnen wenig bringen und eigenständig weiter arbeiten möchten. Auf diese Art und Weise haben wir dann auch bis zum Ende weiter gearbeitet.

Projektmanagement ist als Student schwer, weil man auf die intrinsische Motivation der Teammitglieder hoffen muss. Manager in der Industrie haben richtige Druckmittel (Mitarbeiter feuern) oder extrinische Motivation (Lohn). Beides kann ich als studentischer Leiter nicht einsetzen. Zusätzlich ist es auch so, dass harte Arbeit und Engagement mit noch mehr Arbeit bestraft wird, weil sich diese Person als verlässlich herausgestellt hat. Es lohnt sich für Gruppenarbeiten also mehr, wenn man nichts macht, weil man am Ende \"doch immer besteht\".

Das Dialogsystem, an dem Lisa und Sophie gearbeitet haben, wurde nicht rechtzeitig fertig weil es noch in das ECS integriert werden musste und das eine sehr zeitaufwendige Aufgabe ist. Ich wurde damit beauftragt einen Abschnitt zu schreiben, wie das passiert ist und deswegen habe ich mir die Git-Historie näher angeschaut. Generell habe ich darauf geachtet, dass sich die einzelnen Feature Branches nicht zu weit voneinander entfernen. Deswegen habe ich am 09.10.2023 alle Branches in den Master gemerged und danach den Master wieder in alle Featurebranches. Damit war der komplette Projektstand synchronisiert und die beiden hätten anfangen können das Dialogsystem in das Entity Component System zu integrieren. Wir haben aber gemeinsam entschieden, dass wir noch Zeit haben und das Dialogsystem zuerst fertig gestellt werden soll. Die beiden haben dann am 05.12.2023 begonnen das Dialogsystem in das Entity Component System zu integrieren. Rückblickend wäre es sinnvoller gewesen zuerst die Integration zu machen und danach das Dialogsystem fertig zu stellen.

Carlo hat das Praktikum vor der Bewertung abgebrochen, weil er nicht genügend Zeit hatte, um einen sinnvollen Beitrag zu leisten. Er war der mit der meisten C++ Erfahrung und arbeitet 18 Stunden in der Woche als Werkstudent, weswegen er die Aufgabe mit der größten unsicherheit an Komplexität lösen sollte. Seine Aufgabe war das Pathfinding System in CrossForge zu integrieren. Aufgrund von Studium, Arbeit, Umzug, Problemen mit seiner Entwicklungsumgebung und mäßiger Dokumentation von Detour hat er nur sehr langsam Fortschritt gemacht.  Bei der Retrospektive haben wir über diese Probleme gesprochen und ich habe ihm vorgeschlagen eine andere, leichtere Aufgabe zu übernehmen. Er wollte nochmal einen Anlauf wagen hat aber dann nach zwei Wochen mein Angebot angenommen. Ich habe seine Aufgabe übernommen und er sollte als nächstes das Partikelsystem implementieren. Durch seine kontinuierlichen IDE Probleme hat er aber die Lust am programmieren verloren. Das Partikelsystem hat dann Leon implementiert und Carlo sollte ab 12.12.2023 Angelique bei den Modellen und einer hübscheren Szene helfen. Er hat in der Woche vor Weihnachten noch die bestehende Szene ein wenig verbessert. Dann waren Weihnachtsferien und im Januar haben wir uns voll dem Bericht schreiben gewidmet. Somit hatte Carlo keine Chance mehr, genug zum Projekt beizutragen, um das Praktikum zu bestehen.
